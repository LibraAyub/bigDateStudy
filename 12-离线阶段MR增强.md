# 12-离线阶段MR增强

## 1.元数据管理概述

###  1.1 NameNode

```
HDFS元数据NameNode 维护整个文件系统元数据。
	fsimage镜像文件:是元数据的一个持久化的检查点，包含 Hadoop 文件系统中的所有目录和文件元数据信息，但不包含文件块位置的信息。
	Edits 编辑日志：存放的是 Hadoop 文件系统的所有更改操作的日志，文件系统客户端执行的更改操作首先会被记录到 edits 文件中。
	fsimage 和 edits 文件都是经过序列化的，在 NameNode 启动的时候，它会将 fsimage文件中的内容加载到内存中.客户对hdfs进行操作时首先存入的是edits日志。
	HDFS 这种设计实现着手于：一是内存中数据更新、查询快，极大缩短了操作响应时间；二是内存中元数据丢失风险颇高（断电等），因此辅佐元数据镜像文件（fsimage）+编辑日志文件（edits）的备份机制进行确保元数据的安全。
```
###  1.2 目录结构

```
在 Hadoop 的 HDFS 首次部署好配置文件之后，并不能马上启动使用，而是先要对文件系统进行格式化。需要在 NameNode（NN）节点上进行如下的操作：
	$HADOOP_HOME/bin/hdfs namenode –format
	格式化其实就是生成current目录下的文件。其实也正是namenode元数据的文件目录。
	namespaceID/clusterID/blockpoolID 这些都是 HDFS 集群的唯一标识符。
	storageType 说明这个文件存储的是什么进程的数据结构信息
	cTime NameNode 存储系统创建时间。
	layoutVersion 表示 HDFS 永久性数据结构的版本信息，是一个负整数。
	Fsimage & edits ：$dfs.namenode.name.dir/current 目录下在 format 的同时也会生成 fsimage 和 edits文件，及其对应的 md5 校验文件。
```

###  1.3 secondary namenode

```
NameNode 职责是管理元数据信息，DataNode 的职责是负责数据具体存储。edits 文件会变的很大，NameNode重启会花费很长时间。如果 NameNode 挂掉了，那就丢失了一些改动。
```

```
因此为了克服这个问题，我们需要一个易于管理的机制来帮助我们减小 edit logs 文件的大小和得到一个最新的 fsimage 文件，这样也会减小在 NameNode 上的压力。SecondaryNameNode 就是来帮助解决上述问题的，它的职责是合并 NameNode 的 edit logs 到 fsimage 文件中。
```

```
secondary namenode 将 namenode 上积累的所有 edits 和一个最新的 fsimage 下载到本地，并加载到内存进行 merge（这个过程称为 checkpoint）。
```

####  	1.3.1 Checkpoint 详细步骤

```
NameNode 管理着元数据信息，其中有两类持久化元数据文件：edits操作日志文件和fsimage元数据镜像文件。
有 dfs.namenode.checkpoint.period 和dfs.namenode.checkpoint.txns 两个配置，只要达到这两个条件任何一个，secondarynamenode 就会执行 checkpoint 的操作。
当触发 checkpoint 操作时，NameNode会生成一个新的edits 。同时 SecondaryNameNode 会将 edits 文件和 fsimage 复制到本地（HTTP GET 方式）。
 secondarynamenode 将下载下来的 fsimage 载入到内存，使得内存中的fsimage保存最新。这个过程就是 edits 和 fsimage文件合并，生成一个新的 fsimage 文件即上图中的 Fsimage.ckpt 文件。
secondarynamenode 将新生成的 Fsimage.ckpt 文件复制到 NameNode 节点。
在 NameNode 节点的 edits.new 文件和 Fsimage.ckpt 文件会替换掉原来的 edits 文件和 fsimage 文件，至此刚好是一个轮回，即在 NameNode 中又是 edits 和 fsimage 文件。
等待下一次checkpoint触发 SecondaryNameNode 进行工作，一直这样循环操作。
```

#### 	1.3.2触发条件

```
core-site.xml 进行配置  两次连续checkpoint之间的时间间隔，默认1小时。
最大的没有执行checkpoint事务的数量，满足强制执行紧急checkpoint默认100万。
```

###  1.4 注意

```
如果 NameNode 中的 fsimage 真的出问题了，还是可以用 SecondaryNamenode 中的 fsimage 替换一下 NameNode 上的 fsimage，虽然已经不是最新的 fsimage，但是我们可以将损失减小到最少！ 
```

## 2 HDFS安全模式

```
安全模式是 HDFS 所处的一种特殊状态，在这种状态下，文件系统只接受读数据请求，而不接受删除、修改等变更请求，是一种保护机制，用于保证集群中的数据块的安全性。
	hdfs-default.xml中定义了一个最小的副本的副本率0.999.
	如果 HDFS 处于安全模式下，不允许 HDFS 客户端进行任何修改文件的操作。
```

## 2 Hadoop High Availability

```
hadoop中存在namenode的单点故障和ResourceManager的单点故障。
```

### 2.1 Namenode HA

```
QJM/Qurom Journal Manager，基本原理就是用 2N+1 台 JournalNode 存储 EditLog，每次写数据操作有>=N+1 返回成功时即认为该次写成功，数据不会丢失了。
	在 HA 架构里面 SecondaryNameNode 已经不存在了，为了保持 standby NN 时时的与 Active NN 的元数据保持一致，他们之间交互通过 JournalNode 进行操作同步。
	在 HA 模式下，datanode 需要确保同一时间有且只有一个 NN 能命令 DN。为此：
	每个 NN 改变状态的时候，向 DN 发送自己的状态和一个序列号。
```

### 2.2 Failover Controller

```
主要包括三个组件：
	HealthMonitor:监控NameNode是否处于 unavailable 状态。
	ActiveStandbyElector: 监控 NN 在 ZK 中的状态。
	ZKFailoverController: 订阅 HealthMonitor 和 ActiveStandbyElector 的事件，并管理 NN 的状态,另外 zkfc 还负责解决 fencing（也是脑裂问题）。
	脑裂：避免同一时刻多个nn的存在。或者大家都不活跃。同一时刻有且只有一个活跃的。
```

#### 	2.2.1 ZKFailoverController 主要职责

```
	健康监测：周期性的向它监控的nn发送健康探测命令。
	会话管理：如果nn是健康的，zkfc就会在zookeeper中保持一个打开的会话。如果 NameNode 同时还是 Active 状态的，那么 zkfc 还会在 Zookeeper 中占有一个类型为短暂类型的 znode，当这个 NN 挂掉时，这个 znode 将会被删除，然后备用的NN 将会得到这把锁，升级为主 NN，同时标记状态为 Active
	master选举：通过在 zookeeper 中维持一个短暂类型的 znode，来实现抢占式的锁机制，从而判断那个 NameNode 为 Active 状态。
```